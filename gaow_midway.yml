DSC:
  midway2:
    description: UChicago RCC cluster Midway 2
    address: gaow@midway2.rcc.uchicago.edu
    paths:
      home: /home/{user_name}
    queue_type: pbs
    status_check_interval: 60
    max_running_jobs: 150
    max_cores: 40
    max_walltime: "36:00:00"
    max_mem: 64G
    job_template: |
      #!/bin/bash
      #SBATCH --time={walltime}
      #{partition}
      #{account}
      #SBATCH --nodes=1
      #SBATCH --ntasks-per-node={cores}
      #SBATCH --mem-per-cpu={mem//10**9}G
      #SBATCH --job-name={job_name}
      #SBATCH --output={job_name}.out
      #SBATCH --error={job_name}.err
      cd {cur_dir}
      module load R/3.5.1 2> /dev/null
    partition: "SBATCH --partition=broadwl"
    account: ""
    submit_cmd: sbatch {job_file}
    submit_cmd_output: "Submitted batch job {job_id}"
    status_cmd: squeue --job {job_id}
    kill_cmd: scancel {job_id}
  midway2_head:
    based_on: midway2
    address: localhost
  stephenslab:
    based_on: midway2
    max_cores: 28
    max_mem: 128G
    max_walltime: "10d"
    partition: "SBATCH --partition=mstephens"
    account: "SBATCH --account=pi-mstephens"

default:
  queue: midway2_head
  time_per_instance: 5m
  instances_per_job: 20
  n_cpu: 1
  mem_per_cpu: 2G

full_data:
  time_per_instance: 10m
  instances_per_job: 10

susie10:
  time_per_instance: 10m
  instances_per_job: 15

caviar_in_sample:
  n_cpu: 2
  time_per_instance: 4h
  instances_per_job: 1

finemap_in_sample:
  time_per_instance: 30m
  instances_per_job: 5

finemapv3_in_sample:
  time_per_instance: 40m
  instances_per_job: 5

# For P = 10,000, causal = 10, DAP needs 120m!
# need to make a separate file to run that.
dap:
  time_per_instance: 20m
  instances_per_job: 10

score_susie:
  time_per_instance: 3m
  instances_per_job: 30

score_dap:
  time_per_instance: 3m
  instances_per_job: 30

score_caviar:
  time_per_instance: 3m
  instances_per_job: 30

score_finemap:
  time_per_instance: 3m
  instances_per_job: 30

score_finemapv3:
  time_per_instance: 3m
  instances_per_job: 30
